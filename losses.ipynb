{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32a23baa-668c-4c3c-886c-4e23577ca877",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595d57d4-d593-48ff-9956-e473cfbc6e8f",
   "metadata": {},
   "source": [
    "### Bernoulli variable - Log Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299ebcc3-4d36-4aa0-a9d9-11f2d21d6129",
   "metadata": {},
   "source": [
    "As discussed before, Bernoulli Random Variables $X \\sim \\textbf{Bern}(p)$ has a probability $p$ of turning up $1$ and $1-p$ of turning up $0$.\n",
    "\n",
    "For succintness, we can rewrite the probability mass function as:\n",
    "$$f(x;p) = p^x (1-p)^{1-x}$$\n",
    "\n",
    "Deciphering this, we see that if $x=1$, the probability is $p$; if $x=0$, the probability is $1-p$.\n",
    "\n",
    "<ins>Example 1: Biased coin toss</ins>\n",
    "\n",
    "Assume we have 100 tosses of a biased coin, and we are trying to estimate the probability $p$ of the coin turning up $H$. We have $68 H$. How do we estimate the probability $p$? We can use an MLE approach:\n",
    "$$L(x;p) = \\prod_{i=1}^{100} p^{x_i} (1-p)^{1-x_i}$$\n",
    "$$\\ln{L(x;p)} = \\sum_{i=1}^{100} x_i\\ln{p} + (1-x_i)\\ln{(1-p)}$$\n",
    "\n",
    "We have recovered the Log-Likehood function, by definition, the Log-Loss function:\n",
    "$$\\ln{\\text{Loss}} = -\\frac{1}{100} \\sum_{i=1}^{100} x_i\\ln{p} + (1-x_i)\\ln{(1-p)}$$\n",
    "\n",
    "It is quite easy now to rewrite the Log-Likelihood function as:\n",
    "$$\\ln{L(x;p)} = 68 \\ln{p} + 32 \\ln{(1-p)}$$\n",
    "$$\\implies \\frac{\\partial \\ln{L(x;p)}}{\\partial p} = \\frac{68}{p} - \\frac{32}{1-p} = 0 \\implies p = \\frac{17}{25}$$\n",
    "\n",
    "The significance of the Log-Loss function is for classification tasks. Assume that we have two types of images: dog and not-dog. The classifier is trying to identify whether an image is a dog or not. Hence, this problem is identical to estimating the probability an image is a dog $(H)$ or  not a dog $(T)$-- a Bernoulli random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b27d9f-5016-4710-8de8-81493b41c053",
   "metadata": {},
   "source": [
    "### Least squares - Mean Squared Error Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a2eb9-ad8c-4377-bad9-c354e0f6869a",
   "metadata": {},
   "source": [
    "As we saw in regression type problems, the mean squared error:\n",
    "$$L = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y_i})^2=\\frac{1}{n} \\sum_{i=1}^n (y_i - \\beta x_i)^2$$\n",
    "\n",
    "However, to think of the mean squared error loss function in terms of a MLE-type problem, we can write out the original regression equation:\n",
    "$$\\hat{y} = \\beta x + \\epsilon$$\n",
    "\n",
    "Assume that $\\epsilon \\sim N(0, \\sigma^2)$, hence $y - \\beta x \\sim N(0, \\sigma^2)$. If we have $n$ data points and we were to fit a gaussian likelihood function of $\\mu=0$ and $\\sigma$, then the likelihood function can be written as:\n",
    "$$L(x; \\beta, \\sigma) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}\\exp{-\\frac{(y_i - \\beta x_i)^2}{2\\sigma^2}}$$\n",
    "$$\\implies \\ln{L(x; \\beta, \\sigma)} = \\sum_{i=1}^n -\\ln{\\sigma} - \\frac{(y_i - \\beta x_i)^2}{2\\sigma^2}$$\n",
    "After $\\arg \\max_{\\beta, \\sigma}$:\n",
    "$$\\beta = \\frac{\\sum_{i=1}^n x_i y_i}{\\sum_{i=1}^n x_i x_i}$$\n",
    "$$\\sigma^2 = \\frac{\\sum_{i=1}^n x_i^2}{n}$$\n",
    "\n",
    "Note that when we are differentiating $\\frac{\\partial \\ln L}{\\partial \\beta}$, the optimization only depends on the 2nd term $\\sum_{i=1}^n \\frac{1}{2} (y_i - \\beta x_i)^2$ (since $\\sigma^2$ is always >0, we can drop that). Therefore, we have shown that maximizing the log-likelihood, with the assumption that the error term $\\epsilon \\sim N(0, \\sigma^2)$, is the same as minimizing the mean-squared error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
